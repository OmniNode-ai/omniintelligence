[tool:pytest]
# Pytest configuration for Archon Integration Test Suite

# Test discovery
testpaths = tests
python_files = test_*.py *_test.py
python_classes = Test*
python_functions = test_*

# Output formatting
addopts =
    -ra
    --strict-markers
    --strict-config
    --disable-warnings
    --tb=short
    --maxfail=5
    --durations=10
    --cov=services
    --cov-report=html:test-reports/coverage
    --cov-report=xml:test-results/coverage.xml
    --cov-report=term-missing
    --junit-xml=test-results/junit.xml
    --html=test-reports/report.html
    --self-contained-html

# Markers for test categorization
markers =
    unit: Unit tests
    integration: Integration tests
    e2e: End-to-end tests
    performance: Performance and load tests
    sla: SLA compliance tests
    happy_path: Happy path scenarios
    error_handling: Error handling tests
    data_consistency: Data consistency validation
    smoke: Smoke tests for basic functionality
    slow: Tests that take more than 10 seconds
    critical: Critical path tests that must pass
    docker: Tests requiring Docker environment
    external: Tests requiring external services
    flaky: Tests that may be flaky/unreliable

# Test timeouts
timeout = 300
timeout_method = thread

# Asyncio configuration
asyncio_mode = auto
asyncio_default_fixture_loop_scope = session

# Parallel execution
# -n auto uses number of CPU cores
# Can be overridden with pytest -n 4

# Logging
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

# Filter warnings
filterwarnings =
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
    ignore:.*urllib3.*:UserWarning
    ignore:.*aiohttp.*:UserWarning

# Minimum test version
minversion = 7.0

# Test collection configuration
collect_ignore =
    setup.py
    conftest.py

# Custom test result reporting
json_report = test-results/report.json
json_report_summary = true

# Performance benchmarking
benchmark-columns = min,max,mean,stddev,median,iqr,outliers,ops,rounds,iterations
benchmark-group-by = group,func,param
benchmark-sort = mean
benchmark-save = test-results/benchmarks
benchmark-autosave = true
