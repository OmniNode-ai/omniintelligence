[pytest]
# Pytest configuration for Intelligence Service tests

# Python path configuration (root of intelligence service - one level up from tests)
# Include src, models, tests (for fixtures), and project root for imports
# IMPORTANT: src must come FIRST to prioritize new structure over legacy root modules
pythonpath = ../src .. .

# Test discovery
testpaths = integration performance unit pattern_learning services
python_files = test_*.py benchmark_*.py
python_classes = Test*
python_functions = test_*

# Output
addopts =
    -v
    --tb=short
    --strict-markers
    -p no:cacheprovider

# Warning filters
filterwarnings =
    # Ignore specific third-party warnings we can't control
    ignore::DeprecationWarning:pydantic.*
    ignore::DeprecationWarning:omnibase_core.*
    ignore::PendingDeprecationWarning
    # Ignore coverage warnings
    ignore::pytest.PytestUnraisableExceptionWarning
    # Show our own code warnings
    default::DeprecationWarning:services.*
    default::DeprecationWarning:handlers.*

# Markers
markers =
    asyncio: mark test as async
    benchmark: mark test as performance benchmark
    integration: mark test as integration test (full request/response cycles)
    performance: mark test as performance benchmark
    unit: mark test as unit test
    slow: mark test as slow running (>5s execution time)
    requires_kafka: mark test as requiring Kafka/Redpanda connection
    requires_db: mark test as requiring database connection
    requires_auth: mark test as requiring authentication
    handler_tests: mark test as handler-specific integration test
    requires_langextract: mark test as requiring LangExtract service
    analysis_handler: mark test as CodegenAnalysisHandler test
    pattern_handler: mark test as CodegenPatternHandler test
    mixin_handler: mark test as CodegenMixinHandler test
    error_handling: mark test as error handling and recovery test
    concurrent: mark test as concurrent request handling test
    api_test: mark test as API endpoint integration test
    pattern_learning: mark test as pattern learning feature test
    quality_intelligence: mark test as quality intelligence feature test
    performance_intelligence: mark test as performance intelligence feature test
    pattern_traceability: mark test as pattern traceability feature test
    autonomous_learning: mark test as autonomous learning feature test
    phase4_traceability: mark test as Phase 4 traceability API integration test
    traceability_lineage: mark test as lineage tracking test
    traceability_analytics: mark test as analytics computation test
    traceability_execution: mark test as execution log test
    traceability_feedback: mark test as feedback loop test
    autonomous: mark test as autonomous execution API test
    learning_feedback: mark test as learning feedback loop test
    custom_rules: mark test as custom quality rules feature test
    wave4: mark test as Wave 4 HTTP implementation test
    wave5: mark test as Wave 5 HTTP implementation test
    wave6: mark test as Wave 6 HTTP implementation test
    wave8: mark test as Wave 8 HTTP implementation test
    pattern_analytics: mark test as pattern analytics feature test
    quality_trends: mark test as quality trends feature test
    e2e: mark test as end-to-end workflow test
    freshness: mark test as document freshness feature test
    freshness_analysis: mark test as document freshness analysis test
    performance_analytics: mark test as performance analytics API test
    chat: mark test as chat history API test
    knowledge_graph: mark test as knowledge graph API test
    stale_documents: mark test as stale document detection test
    document_refresh: mark test as document refresh feature test
    event_ingestion: mark test as event ingestion test
    event_stats: mark test as event statistics test
    analyses_list: mark test as analyses list endpoint test
    cleanup: mark test as cleanup operation test
    freshness_stats: mark test as freshness statistics test
    single_document: mark test as single document operation test

# Async settings
asyncio_mode = auto
asyncio_default_fixture_loop_scope = function

# Timeouts (default 30s for integration tests)
timeout = 30
timeout_method = thread

# Coverage
[coverage:run]
source = src
omit =
    */tests/*
    */test_*.py
    */__pycache__/*

[coverage:report]
precision = 2
show_missing = True
skip_covered = False

[coverage:html]
directory = htmlcov
