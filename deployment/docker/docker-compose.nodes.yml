---
# ============================================================================
# OmniIntelligence - ONEX Nodes
# ============================================================================
# Purpose: ONEX 4.0 node deployments (orchestrator, reducer, compute, effect)
# Dependencies: Requires docker-compose.yml (base infrastructure) running
# Usage: docker compose -f docker-compose.yml -f docker-compose.nodes.yml up -d
#
# Health Checks:
# - All nodes expose HTTP /health endpoint on port 8000
# - Node Dockerfiles install curl for healthcheck support
# - Nodes start in "stub mode" with health checks until ONEX container injection
#
# Network:
# - Uses external network 'omniintelligence_omni-network' from base compose
# - Nodes communicate with infrastructure via container names (postgres, qdrant, etc.)
# ============================================================================

name: omniintelligence

services:

  # ============================================================================
  # Intelligence Reducer - Pure FSM State Management
  # ============================================================================

  intelligence-reducer:
    build:
      context: ../..
      dockerfile: deployment/docker/Dockerfile.reducer
    container_name: omni-intelligence-reducer
    environment:
      # Database Configuration
      DATABASE_URL: ${DATABASE_URL:-postgresql://postgres:${POSTGRES_PASSWORD}@postgres:5432/omniintelligence}

      # Reducer Configuration
      ENABLE_LEASE_MANAGEMENT: ${ENABLE_LEASE_MANAGEMENT:-true}
      LEASE_TIMEOUT_SECONDS: ${LEASE_TIMEOUT_SECONDS:-300}
      MAX_RETRY_ATTEMPTS: ${MAX_RETRY_ATTEMPTS:-3}

      # Logging
      LOG_LEVEL: ${LOG_LEVEL:-INFO}

    networks:
      - omni-network
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      # Node Dockerfiles install curl - safe to use for healthcheck
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'

  # ============================================================================
  # Intelligence Orchestrator - Llama Index Workflows
  # ============================================================================

  intelligence-orchestrator:
    build:
      context: ../..
      dockerfile: deployment/docker/Dockerfile.orchestrator
    container_name: omni-intelligence-orchestrator
    environment:
      # Orchestrator Configuration
      MAX_CONCURRENT_WORKFLOWS: ${MAX_CONCURRENT_WORKFLOWS:-10}
      WORKFLOW_TIMEOUT_SECONDS: ${WORKFLOW_TIMEOUT_SECONDS:-300}
      ENABLE_CACHING: ${ENABLE_CACHING:-true}
      CACHE_TTL_SECONDS: ${CACHE_TTL_SECONDS:-300}

      # Dependencies
      REDUCER_URL: http://intelligence-reducer:8000
      VALKEY_URL: redis://:${VALKEY_PASSWORD}@valkey:6379/0

      # Logging
      LOG_LEVEL: ${LOG_LEVEL:-INFO}

    networks:
      - omni-network
    depends_on:
      intelligence-reducer:
        condition: service_healthy
      valkey:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'

  # ============================================================================
  # Vectorization Compute Node
  # ============================================================================

  vectorization-compute:
    build:
      context: ../..
      dockerfile: deployment/docker/Dockerfile.compute
      args:
        NODE_NAME: vectorization_compute
    container_name: omni-vectorization-compute
    environment:
      DEFAULT_MODEL: ${EMBEDDING_MODEL:-text-embedding-3-small}
      MAX_BATCH_SIZE: ${VECTORIZATION_BATCH_SIZE:-100}
      ENABLE_CACHING: ${ENABLE_CACHING:-true}
      CACHE_TTL_SECONDS: ${CACHE_TTL_SECONDS:-3600}
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
    networks:
      - omni-network
    depends_on:
      valkey:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'

  # ============================================================================
  # Quality Scoring Compute Node
  # ============================================================================

  quality-scoring-compute:
    build:
      context: ../..
      dockerfile: deployment/docker/Dockerfile.compute
      args:
        NODE_NAME: quality_scoring_compute
    container_name: omni-quality-scoring-compute
    environment:
      ONEX_VALIDATION_ENABLED: ${ONEX_VALIDATION_ENABLED:-true}
      GENERATE_RECOMMENDATIONS: ${GENERATE_RECOMMENDATIONS:-true}
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
    networks:
      - omni-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'

  # ============================================================================
  # Qdrant Vector Effect Node
  # ============================================================================

  qdrant-vector-effect:
    build:
      context: ../..
      dockerfile: deployment/docker/Dockerfile.effect
      args:
        NODE_NAME: qdrant_vector_effect
    container_name: omni-qdrant-vector-effect
    environment:
      QDRANT_URL: ${QDRANT_URL:-http://qdrant:6333}
      DEFAULT_COLLECTION: ${QDRANT_DEFAULT_COLLECTION:-archon_vectors}
      VECTOR_DIMENSION: ${VECTOR_DIMENSION:-1536}
      DISTANCE_METRIC: ${DISTANCE_METRIC:-cosine}
      BATCH_SIZE: ${QDRANT_BATCH_SIZE:-100}
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
    networks:
      - omni-network
    depends_on:
      qdrant:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'

  # ============================================================================
  # Memgraph Graph Effect Node
  # ============================================================================

  memgraph-graph-effect:
    build:
      context: ../..
      dockerfile: deployment/docker/Dockerfile.effect
      args:
        NODE_NAME: memgraph_graph_effect
    container_name: omni-memgraph-graph-effect
    environment:
      MEMGRAPH_HOST: ${MEMGRAPH_HOST:-memgraph}
      MEMGRAPH_PORT: ${MEMGRAPH_PORT:-7687}
      ENABLE_INDEXING: ${MEMGRAPH_ENABLE_INDEXING:-true}
      BATCH_SIZE: ${MEMGRAPH_BATCH_SIZE:-100}
      QUERY_TIMEOUT_SECONDS: ${MEMGRAPH_QUERY_TIMEOUT:-30}
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
    networks:
      - omni-network
    depends_on:
      memgraph:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'

  # ============================================================================
  # PostgreSQL Pattern Effect Node
  # ============================================================================

  postgres-pattern-effect:
    build:
      context: ../..
      dockerfile: deployment/docker/Dockerfile.effect
      args:
        NODE_NAME: postgres_pattern_effect
    container_name: omni-postgres-pattern-effect
    environment:
      DATABASE_URL: ${DATABASE_URL:-postgresql://postgres:${POSTGRES_PASSWORD}@postgres:5432/omniintelligence}
      ENABLE_FULL_TEXT_SEARCH: ${ENABLE_FULL_TEXT_SEARCH:-true}
      ENABLE_LINEAGE_TRACKING: ${ENABLE_LINEAGE_TRACKING:-true}
      BATCH_SIZE: ${PATTERN_BATCH_SIZE:-50}
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
    networks:
      - omni-network
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'

# =============================================================================
# Network Configuration
# =============================================================================
# DEPLOYMENT MODES:
#
# Mode 1: Combined Deployment (RECOMMENDED)
#   docker compose -f docker-compose.yml -f docker-compose.nodes.yml up -d
#   - Files are merged, network definition comes from base docker-compose.yml
#   - Empty network definition here allows proper merging with base file
#   - Services communicate via container names (postgres, qdrant, etc.)
#
# Mode 2: Standalone Node Deployment (requires base infra running first)
#   Step 1: docker compose -f docker-compose.yml up -d  # Start infrastructure
#   Step 2: docker compose -f docker-compose.nodes.yml --project-name omniintelligence up -d
#   - IMPORTANT: Use --project-name to match base compose project name
#   - This ensures nodes join the existing omniintelligence_omni-network
#   - Network already exists from Step 1
#
# WHY NOT external: true?
#   Using external: true here would break combined deployment (Mode 1) because
#   Docker Compose would look for an existing network instead of creating it.
#   The empty definition {} allows proper merging with the base file's full
#   network definition (driver, ipam, subnet).
#
# Network Architecture:
#   - omni-network: Internal bridge network (172.28.0.0/16)
#   - Defined in docker-compose.yml as bridge with custom subnet
#   - All nodes and infrastructure share this network
#   - Container DNS resolution for service discovery
#
# For production with external infrastructure (see ~/.claude/CLAUDE.md):
#   - Override service URLs via environment variables
#   - Connect to remote PostgreSQL (192.168.86.200:5436)
#   - Connect to remote Kafka (192.168.86.200:29092)
# =============================================================================

networks:
  # Empty definition merges cleanly with base compose bridge network
  # Combined mode: Uses bridge definition from docker-compose.yml
  # Standalone mode: Requires --project-name omniintelligence to join existing network
  omni-network: {}
