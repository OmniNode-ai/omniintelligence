# SPDX-FileCopyrightText: 2025 OmniNode.ai Inc.
# SPDX-License-Identifier: MIT
---
# ============================================================================
# OmniIntelligence - ONEX Nodes
# ============================================================================
# Purpose: ONEX 4.0 node deployments (orchestrator, reducer, compute, effect)
#
# Dependencies:
#   omniintelligence owns ZERO data stores. All infrastructure is provided by:
#   - omnibase_infra: PostgreSQL, Kafka/Redpanda, Valkey
#   - omnimemory: Qdrant, Memgraph
#
# Usage:
#   1. Start omnibase_infra first:
#      docker compose -f <omnibase_infra>/docker/docker-compose.infra.yml up -d
#   2. Start omniintelligence nodes:
#      docker compose -f deployment/docker/docker-compose.nodes.yml up -d
#
# Health Checks:
# - All nodes expose HTTP /health endpoint on port 8000
# - Node Dockerfiles install curl for healthcheck support
# - Nodes start in "stub mode" with health checks until ONEX container injection
#
# Network:
# - Uses external network 'omnibase-infra-network' from omnibase_infra
# - Nodes communicate with infrastructure via container names
#   (omnibase-infra-postgres, omnibase-infra-redpanda, etc.)
# ============================================================================

name: omniintelligence

services:

  # ============================================================================
  # Intelligence Reducer - Pure FSM State Management
  # ============================================================================

  intelligence-reducer:
    build:
      context: ../..
      dockerfile: deployment/docker/Dockerfile.reducer
    container_name: omni-intelligence-reducer
    environment:
      # Database Configuration — points to omnibase_infra postgres
      DATABASE_URL: ${DATABASE_URL:-postgresql://postgres:${POSTGRES_PASSWORD}@omnibase-infra-postgres:5432/omnibase_infra}

      # Reducer Configuration
      ENABLE_LEASE_MANAGEMENT: ${ENABLE_LEASE_MANAGEMENT:-true}
      LEASE_TIMEOUT_SECONDS: ${LEASE_TIMEOUT_SECONDS:-300}
      MAX_RETRY_ATTEMPTS: ${MAX_RETRY_ATTEMPTS:-3}

      # Logging
      LOG_LEVEL: ${LOG_LEVEL:-INFO}

    networks:
      - omnibase-infra-network
    healthcheck:
      # Node Dockerfiles install curl - safe to use for healthcheck
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'

  # ============================================================================
  # Intelligence Orchestrator - Llama Index Workflows
  # ============================================================================

  intelligence-orchestrator:
    build:
      context: ../..
      dockerfile: deployment/docker/Dockerfile.orchestrator
    container_name: omni-intelligence-orchestrator
    environment:
      # Orchestrator Configuration
      MAX_CONCURRENT_WORKFLOWS: ${MAX_CONCURRENT_WORKFLOWS:-10}
      WORKFLOW_TIMEOUT_SECONDS: ${WORKFLOW_TIMEOUT_SECONDS:-300}
      ENABLE_CACHING: ${ENABLE_CACHING:-true}
      CACHE_TTL_SECONDS: ${CACHE_TTL_SECONDS:-300}

      # Dependencies — points to omnibase_infra valkey
      REDUCER_URL: http://intelligence-reducer:8000
      VALKEY_URL: redis://:${VALKEY_PASSWORD}@omnibase-infra-valkey:6379/0

      # Logging
      LOG_LEVEL: ${LOG_LEVEL:-INFO}

    networks:
      - omnibase-infra-network
    depends_on:
      intelligence-reducer:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'

  # ============================================================================
  # Quality Scoring Compute Node
  # ============================================================================

  quality-scoring-compute:
    build:
      context: ../..
      dockerfile: deployment/docker/Dockerfile.compute
      args:
        NODE_NAME: quality_scoring_compute
    container_name: omni-quality-scoring-compute
    environment:
      ONEX_VALIDATION_ENABLED: ${ONEX_VALIDATION_ENABLED:-true}
      GENERATE_RECOMMENDATIONS: ${GENERATE_RECOMMENDATIONS:-true}
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
    networks:
      - omnibase-infra-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'

# =============================================================================
# Network Configuration
# =============================================================================
# omniintelligence attaches to the omnibase_infra external network.
# That network is created when omnibase_infra starts:
#
#   docker compose -f <omnibase_infra>/docker/docker-compose.infra.yml up -d
#
# Do NOT start infrastructure from this repo — omniintelligence is a pure
# application service and owns zero data stores.
# =============================================================================

networks:
  omnibase-infra-network:
    external: true
