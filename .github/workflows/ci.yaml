# SPDX-FileCopyrightText: 2025 OmniNode.ai Inc.
# SPDX-License-Identifier: MIT

name: CI

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:

env:
  PYTHON_VERSION: "3.12"
  UV_VERSION: "0.5.14"
  CACHE_VERSION: "0.1.0"

# ============================================================================
# CI-PRECOMMIT ALIGNMENT NOTICE - KEEP IN SYNC WITH .pre-commit-config.yaml
# ============================================================================
#
# OVERVIEW:
# This workflow uses path-based filtering to run production code jobs only when
# relevant files change. These paths must stay synchronized with pre-commit hooks.
#
# CURRENT SCOPE:
# - Source directories: tools/, utils/, runtime/
# - Test directories: tests/unit/tools/, tests/unit/test_log_sanitizer.py
#
# ALIGNED PATTERNS (must stay synchronized):
# 1. CI production_code filter (changes job): glob patterns for path detection
# 2. Pre-commit ruff/mypy files: regex patterns for hook filtering
# 3. CI lint/type-check job paths: explicit paths for commands
# 4. Mypy cache hashFiles: glob patterns for cache invalidation
#
# INTENTIONAL SCOPE DIFFERENCES:
# - Path filter (broad): Triggers jobs on any production code change
# - Pytest scope (narrow): Only runs tests/unit/tools/ (mature tests only)
# - See test-unit job comments for detailed rationale and expansion TODO
#
# VALIDATION:
# - Automated: scope-alignment job runs on every CI build
# - Manual: uv run python scripts/validate_ci_precommit_alignment.py --verbose
# - Script detects drift between CI globs and pre-commit regex patterns
#
# ADDING A NEW MODULE:
# When adding a new source directory (e.g., models/), update ALL of these:
#
# 1. CI production_code filter (this file, changes job filters):
#    Add: - 'src/omniintelligence/newmodule/**'
#
# 2. CI lint job paths (ruff check and ruff format commands):
#    Add: src/omniintelligence/newmodule/ \
#
# 3. CI type-check job - mypy cache hashFiles (~line 272):
#    Add: 'src/omniintelligence/newmodule/**/*.py' to the hashFiles() call
#    IMPORTANT: hashFiles patterns must match the mypy command scope
#
# 4. CI type-check job - mypy command:
#    Add: src/omniintelligence/newmodule/
#
# 5. Pre-commit ruff/mypy files pattern (.pre-commit-config.yaml):
#    Update regex: (tools|utils|runtime|newmodule)
#
# 6. Validation script canonical list (scripts/validate_ci_precommit_alignment.py):
#    Add 'newmodule' to ALIGNED_SOURCE_DIRS
#
# MYPY CACHE STRATEGY:
# The mypy cache key includes hashes of all Python files in the checked scope.
# This ensures cache invalidation when source files change, while allowing
# cache reuse when only unrelated files change. The hashFiles patterns MUST
# match the directories passed to the mypy command:
#   - hashFiles: 'src/omniintelligence/{tools,utils,runtime}/**/*.py'
#   - mypy command: src/omniintelligence/{tools,utils,runtime}/
#
# Note: pre-commit and contract-validation run on all changes (no path filter)
# ============================================================================

jobs:
  # Detect which files changed to conditionally run production code jobs
  changes:
    name: Detect Changes
    runs-on: ubuntu-latest
    # Permissions required for dorny/paths-filter to access PR file list via GitHub API
    # Scoped to this job only (security best practice - least privilege)
    permissions:
      contents: read
      pull-requests: read
    outputs:
      # NOTE: Output name uses underscores (production_code) intentionally.
      # GitHub Actions outputs work reliably with underscores; hyphens can cause
      # issues in expression contexts. This naming is correct per GitHub docs.
      production_code: ${{ steps.filter.outputs.production_code }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Check for production code changes
        uses: dorny/paths-filter@v3
        id: filter
        with:
          # Scope aligned with pre-commit hooks (tools/, utils/, runtime/ and their tests)
          filters: |
            production_code:
              - 'src/omniintelligence/tools/**'
              - 'src/omniintelligence/utils/**'
              - 'src/omniintelligence/runtime/**'
              - 'tests/unit/tools/**'
              - 'tests/unit/test_log_sanitizer.py'
              - 'pyproject.toml'
              - 'uv.lock'
              - '.github/workflows/ci.yaml'

  # Assert no Poetry artifacts - enforces uv-only build toolchain
  assert-no-poetry:
    name: Assert No Poetry Artifacts
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Assert no Poetry artifacts
        run: |
          test ! -f poetry.lock || { echo "ERROR: poetry.lock must not exist — use uv.lock"; exit 1; }
          python3 -c "
          import tomllib
          with open('pyproject.toml', 'rb') as f: d = tomllib.load(f)
          backend = d.get('build-system', {}).get('build-backend', '')
          assert 'poetry' not in backend, f'ERROR: poetry build backend found: {backend}'
          assert 'version' not in d.get('tool', {}).get('poetry', {}), 'ERROR: [tool.poetry].version must not exist'
          print('OK: build config is clean')
          "

  # Pre-commit hooks - comprehensive code quality validation
  pre-commit:
    name: Pre-commit Hooks
    runs-on: ubuntu-latest
    timeout-minutes: 20

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install uv
        uses: astral-sh/setup-uv@v7
        with:
          version: ${{ env.UV_VERSION }}
          enable-cache: true
          cache-dependency-glob: "uv.lock"

      - name: Cache uv dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/uv
          key: >-
            uv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-
            ${{ hashFiles('**/uv.lock') }}-
            ${{ env.CACHE_VERSION }}
          restore-keys: |
            uv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-${{ hashFiles('**/uv.lock') }}-
            uv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-

      - name: Install dependencies
        run: uv sync --group dev --group core

      - name: Cache pre-commit hooks
        uses: actions/cache@v4
        with:
          path: ~/.cache/pre-commit
          key: >-
            pre-commit-${{ runner.os }}-${{ env.PYTHON_VERSION }}-
            ${{ hashFiles('.pre-commit-config.yaml') }}
          restore-keys: |
            pre-commit-${{ runner.os }}-${{ env.PYTHON_VERSION }}-

      # Verbose mode enables hook profiling - shows execution time for each hook
      # This helps identify slow hooks and track performance regressions
      # See .pre-commit-config.yaml for profiling documentation and thresholds
      - name: Run pre-commit hooks
        run: |
          echo "Starting pre-commit hooks with profiling..."
          time uv run pre-commit run --all-files --show-diff-on-failure --verbose

  # Validate CI and pre-commit scope alignment
  # Ensures path filters in CI match file patterns in pre-commit hooks
  # Fast check (~1s) that catches configuration drift before it causes issues
  scope-alignment:
    name: Scope Alignment
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install uv
        uses: astral-sh/setup-uv@v7
        with:
          version: ${{ env.UV_VERSION }}
          enable-cache: true
          cache-dependency-glob: "uv.lock"

      - name: Cache uv dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/uv
          key: >-
            uv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-
            ${{ hashFiles('**/uv.lock') }}-
            ${{ env.CACHE_VERSION }}
          restore-keys: |
            uv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-${{ hashFiles('**/uv.lock') }}-
            uv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-

      - name: Install dependencies
        run: uv sync --group dev

      - name: Validate CI-precommit scope alignment
        run: |
          echo "Validating alignment between CI path filters and pre-commit patterns..."
          uv run python scripts/validate_ci_precommit_alignment.py --verbose

  # Lint job - ruff check and format validation
  # Scope aligned with pre-commit hooks (tools/, utils/, runtime/ and their tests)
  # Only runs when production code changes
  lint:
    name: Lint
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: changes
    if: needs.changes.outputs.production_code == 'true'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install uv
        uses: astral-sh/setup-uv@v7
        with:
          version: ${{ env.UV_VERSION }}
          enable-cache: true
          cache-dependency-glob: "uv.lock"

      - name: Cache uv dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/uv
          key: >-
            uv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-
            ${{ hashFiles('**/uv.lock') }}-
            ${{ env.CACHE_VERSION }}
          restore-keys: |
            uv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-${{ hashFiles('**/uv.lock') }}-
            uv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-

      - name: Install dependencies
        run: uv sync --group dev

      # Scope: Entire codebase (src/ tests/)
      # Matches pre-commit ruff hooks (always_run: true pattern from omnibase_core)
      - name: Run ruff check
        run: uv run ruff check src/ tests/

      - name: Run ruff format check
        run: uv run ruff format --check src/ tests/

  # Type checking job - mypy
  # Scope aligned with pre-commit hooks (tools/, utils/, runtime/ source code)
  # Only runs when production code changes
  type-check:
    name: Type Check
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: changes
    if: needs.changes.outputs.production_code == 'true'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install uv
        uses: astral-sh/setup-uv@v7
        with:
          version: ${{ env.UV_VERSION }}
          enable-cache: true
          cache-dependency-glob: "uv.lock"

      - name: Cache uv dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/uv
          key: >-
            uv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-
            ${{ hashFiles('**/uv.lock') }}-
            ${{ env.CACHE_VERSION }}
          restore-keys: |
            uv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-${{ hashFiles('**/uv.lock') }}-
            uv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-

      - name: Install dependencies
        run: uv sync --group dev --group core

      # Cache mypy's incremental analysis data for faster subsequent runs
      # Without this cache, --incremental flag provides no benefit in CI (fresh containers)
      # Key includes Python version and source file hashes for cache invalidation
      - name: Cache mypy
        uses: actions/cache@v4
        with:
          path: .mypy_cache
          key: >-
            mypy-${{ runner.os }}-${{ env.PYTHON_VERSION }}-
            ${{ hashFiles('src/omniintelligence/tools/**/*.py', 'src/omniintelligence/utils/**/*.py', 'src/omniintelligence/runtime/**/*.py') }}-
            ${{ env.CACHE_VERSION }}
          restore-keys: |
            mypy-${{ runner.os }}-${{ env.PYTHON_VERSION }}-

      # Scope: tools/, utils/, runtime/ source code (not tests)
      # Matches pre-commit mypy hook scope (see .pre-commit-config.yaml)
      - name: Run mypy
        run: |
          uv run mypy \
            src/omniintelligence/tools/ \
            src/omniintelligence/utils/ \
            src/omniintelligence/runtime/

  # Unit tests with coverage
  # Only runs when production code changes
  #
  # TEST SCOPE NOTICE:
  # The pytest scope (tests/unit/tools/) is intentionally narrower than the path
  # filter scope (tools/, utils/, runtime/). This is because:
  #
  # 1. Only tests/unit/tools/ has mature, comprehensive unit tests currently
  # 2. utils/ has only test_log_sanitizer.py (not a full test suite)
  # 3. runtime/ does not have unit tests yet (integration tests pending)
  #
  # The broader path filter ensures the test job RUNS when any production code
  # changes (catching regressions), while the narrow pytest scope prevents CI
  # failures from missing test files.
  #
  # TODO(OMN-XXX): Expand test scope as unit tests are added:
  # - Add tests/unit/utils/ when utils test suite is complete
  # - Add tests/unit/runtime/ when runtime unit tests exist
  # - Update coverage target to include all tested modules
  #
  test-unit:
    name: Unit Tests
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: changes
    if: needs.changes.outputs.production_code == 'true'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install uv
        uses: astral-sh/setup-uv@v7
        with:
          version: ${{ env.UV_VERSION }}
          enable-cache: true
          cache-dependency-glob: "uv.lock"

      - name: Cache uv dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/uv
          key: >-
            uv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-
            ${{ hashFiles('**/uv.lock') }}-
            ${{ env.CACHE_VERSION }}
          restore-keys: |
            uv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-${{ hashFiles('**/uv.lock') }}-
            uv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-

      - name: Install dependencies
        run: uv sync --group dev --group core

      # Scope: tests/unit/tools/ only (see TEST SCOPE NOTICE above)
      # Coverage: tools/ only - expand when more test suites are added
      - name: Run unit tests with coverage
        run: |
          uv run pytest tests/unit/tools/ \
            -v \
            --tb=short \
            --cov=src/omniintelligence/tools \
            --cov-report=xml \
            --cov-report=term-missing \
            --junitxml=junit-unit.xml

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-unit
          path: |
            junit-unit.xml
            coverage.xml
          retention-days: 7

  # Contract validation - validates ONEX contract YAML files
  contract-validation:
    name: Contract Validation
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install uv
        uses: astral-sh/setup-uv@v7
        with:
          version: ${{ env.UV_VERSION }}
          enable-cache: true
          cache-dependency-glob: "uv.lock"

      - name: Cache uv dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/uv
          key: >-
            uv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-
            ${{ hashFiles('**/uv.lock') }}-
            ${{ env.CACHE_VERSION }}
          restore-keys: |
            uv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-${{ hashFiles('**/uv.lock') }}-
            uv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-

      - name: Install dependencies
        run: uv sync --group dev --group core

      - name: Find and validate contracts
        id: contract-validation
        run: |
          # Record start time
          START_TIME=$(date +%s)

          # Find all contract files in nodes directories
          # Searches both current and legacy node locations
          # Pattern matches:
          #   - contract.yaml (canonical ONEX format)
          #   - *_contract.yaml (legacy: compute_contract.yaml, effect_contract.yaml, etc.)
          #   - fsm_*.yaml (FSM subcontracts)
          # Excludes subcontracts/ and workflows/ directories which contain partial contract fragments
          CONTRACT_FILES=$(find src/omniintelligence -type d -name "nodes" -exec \
            find {} -type f \( -name "contract.yaml" -o -name "*_contract.yaml" -o -name "fsm_*.yaml" \) \
              ! -path "*/subcontracts/*" \
              ! -path "*/workflows/*" \; 2>/dev/null | sort)

          # Fail fast if no contracts found - prevents silent CI passes
          if [ -z "$CONTRACT_FILES" ]; then
            echo "::error::No contract files found! This indicates a path or pattern mismatch."
            echo "Searched in: src/omniintelligence/**/nodes/"
            echo "Expected patterns: contract.yaml, *_contract.yaml, fsm_*.yaml"
            exit 1
          fi

          # Count contracts for metrics
          CONTRACT_COUNT=$(echo "$CONTRACT_FILES" | wc -l | tr -d ' ')
          echo "contract_count=$CONTRACT_COUNT" >> $GITHUB_OUTPUT

          echo "Found $CONTRACT_COUNT contract file(s) to validate:"
          echo "$CONTRACT_FILES"
          echo ""

          # Run contract linter on all found files
          echo "Starting contract validation..."
          VALIDATION_START=$(date +%s)

          if uv run python -m omniintelligence.tools.contract_linter --verbose $CONTRACT_FILES; then
            VALIDATION_STATUS="success"
          else
            VALIDATION_STATUS="failed"
          fi

          VALIDATION_END=$(date +%s)
          VALIDATION_DURATION=$((VALIDATION_END - VALIDATION_START))
          echo "validation_duration=${VALIDATION_DURATION}s" >> $GITHUB_OUTPUT

          END_TIME=$(date +%s)
          TOTAL_DURATION=$((END_TIME - START_TIME))
          echo "total_duration=${TOTAL_DURATION}s" >> $GITHUB_OUTPUT

          echo ""
          echo "Contract validation complete in ${VALIDATION_DURATION}s (total step: ${TOTAL_DURATION}s)"

          if [ "$VALIDATION_STATUS" = "failed" ]; then
            exit 1
          fi

  # I/O Audit - ONEX node purity enforcement
  # Validates compute nodes do not contain forbidden I/O patterns (network, env, file)
  # Runs on all changes to catch purity violations early
  io-audit:
    name: I/O Audit
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install uv
        uses: astral-sh/setup-uv@v7
        with:
          version: ${{ env.UV_VERSION }}
          enable-cache: true
          cache-dependency-glob: "uv.lock"

      - name: Cache uv dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/uv
          key: >-
            uv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-
            ${{ hashFiles('**/uv.lock') }}-
            ${{ env.CACHE_VERSION }}
          restore-keys: |
            uv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-${{ hashFiles('**/uv.lock') }}-
            uv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-

      - name: Install dependencies
        run: uv sync --group dev --group core

      - name: Run I/O audit
        run: |
          echo "Running ONEX node purity audit..."
          uv run python -m omniintelligence.audit.io_audit \
            --whitelist tests/audit/io_audit_whitelist.yaml

  # Cross-repo validation - enforces architectural boundaries
  # Prevents direct Kafka imports in nodes/ (must use Protocol abstractions)
  # Reference: ARCH-002 "Runtime owns all Kafka plumbing"
  cross-repo-validation:
    name: Cross-Repo Validation
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install uv
        uses: astral-sh/setup-uv@v7
        with:
          version: ${{ env.UV_VERSION }}
          enable-cache: true
          cache-dependency-glob: "uv.lock"

      - name: Cache uv dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/uv
          key: >-
            uv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-
            ${{ hashFiles('**/uv.lock') }}-
            ${{ env.CACHE_VERSION }}
          restore-keys: |
            uv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-${{ hashFiles('**/uv.lock') }}-
            uv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-

      - name: Install dependencies
        run: uv sync --group core

      - name: Run cross-repo validation
        run: |
          echo "Running cross-repo validation (Kafka import guard)..."
          uv run python -m omnibase_core.validation.cross_repo --policy .cross-repo-policy.yaml

  # Migration freeze enforcement - blocks new migrations when .migration_freeze exists
  # Part of DB-per-repo refactor (OMN-2055), tracking: OMN-2072
  # Deliberately unconditional: no path-filter gating or `needs: changes` dependency.
  # The freeze must be enforced on every PR regardless of which files changed.
  migration-freeze:
    name: Migration Freeze Check
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Check migration freeze
        run: ./scripts/check_migration_freeze.sh --ci

  # ============================================================================
  # Architecture Handshake Verification
  # ============================================================================
  check-handshake:
    name: Verify Architecture Handshake
    runs-on: ubuntu-latest
    # Skip on fork PRs - forks may not have access to cross-repo checkout
    # Runs on: push events, workflow_dispatch, and PRs from the same repo
    if: github.event.pull_request.head.repo.full_name == github.repository || github.event_name != 'pull_request'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Checkout omnibase_core
        uses: actions/checkout@v4
        with:
          repository: OmniNode-ai/omnibase_core
          path: omnibase_core

      - name: Verify handshake is current
        run: |
          echo "::group::Architecture Handshake Verification"
          if [ ! -f "./omnibase_core/architecture-handshakes/check-handshake.sh" ]; then
            echo "::error::check-handshake.sh not found in omnibase_core"
            exit 1
          fi
          echo "Verifying .claude/architecture-handshake.md matches source in omnibase_core..."
          echo ""
          ./omnibase_core/architecture-handshakes/check-handshake.sh ./omnibase_core
          echo "::endgroup::"

  # ============================================================================
  # Detect Secrets - Baseline security scan (OMN-2227)
  # ============================================================================
  # Uses detect-secrets-hook for proper baseline comparison (handles type+hash equality)
  detect-secrets:
    name: Detect Secrets
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      # detect-secrets is a CI-only scanning tool, not a project dependency.
      # Installed via pip (not uv) because it is not declared in pyproject.toml.
      - name: Install detect-secrets
        run: pip install detect-secrets==1.5.0

      - name: Run detect-secrets-hook
        run: |
          # Use detect-secrets-hook with baseline for proper CI enforcement.
          # detect-secrets-hook compares findings against the baseline using the
          # full equality model (hashed_secret + type), and exits non-zero only
          # for NEW secrets not already baselined.
          #
          # Excludes: uv.lock (dependency hashes), .venv/, test fixtures,
          # .git/, .secrets.baseline (contains hashed values that self-trigger),
          # workflow YAML (references "secret" in config context)
          set +e
          git ls-files -z | xargs -0 detect-secrets-hook \
            --baseline .secrets.baseline \
            --exclude-files 'uv\.lock' \
            --exclude-files '\.venv/' \
            --exclude-files 'tests/fixtures/' \
            --exclude-files '\.git/' \
            --exclude-files '\.secrets\.baseline' \
            --exclude-files '\.github/workflows/.*\.ya?ml'  # All workflow YAML legitimately references secrets.* context; individual file exclusions would go stale
          HOOK_EXIT=$?
          set -e

          if [[ $HOOK_EXIT -eq 0 ]]; then
            echo "## Secrets Scan" >> $GITHUB_STEP_SUMMARY
            echo "No new secrets detected (all findings are baselined)." >> $GITHUB_STEP_SUMMARY
          else
            echo "## New Secrets Detected" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "detect-secrets-hook found secrets not present in .secrets.baseline." >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "If these are false positives, regenerate the baseline:" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            echo 'detect-secrets scan --exclude-files "uv\.lock" --exclude-files "\.venv/" --exclude-files "tests/fixtures/" --exclude-files "\.git/" --exclude-files "\.secrets\.baseline" --exclude-files "\.github/workflows/.*\.ya?ml" --force-use-all-plugins > .secrets.baseline' >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            exit 1
          fi

  # ============================================================================
  # Quality Gate - Aggregates all unconditional governance checks (OMN-2227)
  # ============================================================================
  # API-STABLE check_name: "Quality Gate"
  # This is the single required check for branch protection that covers all
  # unconditional governance jobs. Individual job names inside this gate can
  # change without updating branch protection rules.
  quality-gate:
    name: Quality Gate
    runs-on: ubuntu-latest
    needs: [assert-no-poetry, pre-commit, scope-alignment, contract-validation, io-audit, cross-repo-validation, migration-freeze, check-handshake, detect-secrets]
    if: always()

    steps:
      - name: Evaluate quality checks
        run: |
          echo "## Quality Gate Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          nopoetry="${{ needs.assert-no-poetry.result }}"
          precommit="${{ needs.pre-commit.result }}"
          scopealign="${{ needs.scope-alignment.result }}"
          contracts="${{ needs.contract-validation.result }}"
          ioaudit="${{ needs.io-audit.result }}"
          crossrepo="${{ needs.cross-repo-validation.result }}"
          migrationfreeze="${{ needs.migration-freeze.result }}"
          handshake="${{ needs.check-handshake.result }}"
          secrets="${{ needs.detect-secrets.result }}"

          # Report each check
          echo "| Check | Result |" >> $GITHUB_STEP_SUMMARY
          echo "|-------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| No Poetry Artifacts | $nopoetry |" >> $GITHUB_STEP_SUMMARY
          echo "| Pre-commit Hooks | $precommit |" >> $GITHUB_STEP_SUMMARY
          echo "| Scope Alignment | $scopealign |" >> $GITHUB_STEP_SUMMARY
          echo "| Contract Validation | $contracts |" >> $GITHUB_STEP_SUMMARY
          echo "| I/O Audit | $ioaudit |" >> $GITHUB_STEP_SUMMARY
          echo "| Cross-Repo Validation | $crossrepo |" >> $GITHUB_STEP_SUMMARY
          echo "| Migration Freeze | $migrationfreeze |" >> $GITHUB_STEP_SUMMARY
          echo "| Architecture Handshake | $handshake |" >> $GITHUB_STEP_SUMMARY
          echo "| Detect Secrets | $secrets |" >> $GITHUB_STEP_SUMMARY

          # Gate logic: all unconditional checks must pass.
          # check-handshake is skipped on fork PRs -- treat skipped as acceptable.
          FAILED=false

          for check in "$nopoetry" "$precommit" "$scopealign" "$contracts" "$ioaudit" "$crossrepo" "$migrationfreeze" "$secrets"; do
            if [[ "$check" != "success" ]]; then
              FAILED=true
            fi
          done

          # Handshake: accept success or skipped (fork PRs)
          if [[ "$handshake" != "success" ]] && [[ "$handshake" != "skipped" ]]; then
            FAILED=true
          fi

          if [[ "$FAILED" == "false" ]]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Quality Gate: PASSED**" >> $GITHUB_STEP_SUMMARY
            echo "All governance checks passed."
            exit 0
          else
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Quality Gate: FAILED**" >> $GITHUB_STEP_SUMMARY
            echo "Quality gate failed. See individual check results above."
            exit 1
          fi

  # ============================================================================
  # CI Summary - Final aggregator for all gates (OMN-2227)
  # ============================================================================
  # API-STABLE check_name: "CI Summary"
  # Aggregates Quality Gate + path-filtered production code jobs.
  # REQUIRED for this repo because it uses path filtering -- skipped path-filtered
  # jobs need an aggregator that distinguishes "skipped by policy" from
  # "missing due to misconfiguration".
  ci-summary:
    name: CI Summary
    runs-on: ubuntu-latest
    needs: [changes, quality-gate, lint, type-check, test-unit]
    if: always()

    steps:
      - name: Evaluate all gates
        run: |
          echo "## CI Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          quality="${{ needs.quality-gate.result }}"
          lint="${{ needs.lint.result }}"
          typecheck="${{ needs.type-check.result }}"
          unittest="${{ needs.test-unit.result }}"
          production_code_changed="${{ needs.changes.outputs.production_code }}"

          # ── Gate results table ──────────────────────────────────────────────
          echo "| Gate / Job | Result | Notes |" >> $GITHUB_STEP_SUMMARY
          echo "|------------|--------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Quality Gate | $quality | Aggregates all unconditional governance checks |" >> $GITHUB_STEP_SUMMARY

          # ── Path-filtered job evaluation ────────────────────────────────────
          # These jobs use path filtering via the changes job. When no production
          # code files changed, they are legitimately skipped ("skipped by policy").
          # If production code DID change but the job is skipped or missing, that
          # indicates misconfiguration.

          FAILED=false

          # Quality Gate must always pass
          if [[ "$quality" != "success" ]]; then
            FAILED=true
          fi

          evaluate_path_filtered_job() {
            local job_name="$1"
            local result="$2"

            if [[ "$result" == "success" ]]; then
              echo "| $job_name | $result | Ran and passed |" >> $GITHUB_STEP_SUMMARY
            elif [[ "$result" == "skipped" ]] && [[ "$production_code_changed" != "true" ]]; then
              echo "| $job_name | $result | Skipped by policy (no production code changes) |" >> $GITHUB_STEP_SUMMARY
            elif [[ "$result" == "skipped" ]] && [[ "$production_code_changed" == "true" ]]; then
              echo "| $job_name | $result | **MISCONFIGURATION**: production code changed but job was skipped |" >> $GITHUB_STEP_SUMMARY
              FAILED=true
            else
              echo "| $job_name | $result | Failed |" >> $GITHUB_STEP_SUMMARY
              FAILED=true
            fi
          }

          evaluate_path_filtered_job "Lint" "$lint"
          evaluate_path_filtered_job "Type Check" "$typecheck"
          evaluate_path_filtered_job "Unit Tests" "$unittest"

          echo "" >> $GITHUB_STEP_SUMMARY

          # ── Skip enumeration ────────────────────────────────────────────────
          SKIPS=""
          if [[ "$lint" == "skipped" ]] && [[ "$production_code_changed" != "true" ]]; then
            SKIPS="${SKIPS}\n- **Lint**: skipped by policy (no changes in tools/, utils/, runtime/)"
          fi
          if [[ "$typecheck" == "skipped" ]] && [[ "$production_code_changed" != "true" ]]; then
            SKIPS="${SKIPS}\n- **Type Check**: skipped by policy (no changes in tools/, utils/, runtime/)"
          fi
          if [[ "$unittest" == "skipped" ]] && [[ "$production_code_changed" != "true" ]]; then
            SKIPS="${SKIPS}\n- **Unit Tests**: skipped by policy (no changes in tools/, utils/, runtime/)"
          fi

          if [[ -n "$SKIPS" ]]; then
            echo "### Skipped Jobs (by policy)" >> $GITHUB_STEP_SUMMARY
            echo -e "$SKIPS" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi

          # ── Final verdict ───────────────────────────────────────────────────
          if [[ "$FAILED" == "false" ]]; then
            echo "### All CI gates passed" >> $GITHUB_STEP_SUMMARY
            echo "Ready for review and merge." >> $GITHUB_STEP_SUMMARY
            exit 0
          else
            echo "### CI gates FAILED" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Gate results:" >> $GITHUB_STEP_SUMMARY
            echo "  Quality Gate: $quality" >> $GITHUB_STEP_SUMMARY
            echo "  Lint: $lint" >> $GITHUB_STEP_SUMMARY
            echo "  Type Check: $typecheck" >> $GITHUB_STEP_SUMMARY
            echo "  Unit Tests: $unittest" >> $GITHUB_STEP_SUMMARY
            exit 1
          fi
