---
# ONEX Node Contract - Intelligence Orchestrator Node
#
# This orchestrator coordinates intelligence workflows using Llama Index.
# Routes operations via EnumIntelligenceOperationType to appropriate workflows:
#   - DOCUMENT_INGESTION: Vectorize, extract entities, delegate storage to omnimemory
#   - PATTERN_LEARNING: 4-phase (Foundation -> Matching -> Validation -> Traceability)
#   - QUALITY_ASSESSMENT: Score code quality, check ONEX compliance
#   - SEMANTIC_ANALYSIS: Generate embeddings, compute similarity
#   - RELATIONSHIP_DETECTION: Detect and classify relationships, delegate storage to omnimemory
# =============================================================================
contract_version:
  major: 1
  minor: 0
  patch: 0
node_version:
  major: 1
  minor: 0
  patch: 0
name: "node_intelligence_orchestrator"
node_type: "ORCHESTRATOR_GENERIC"
description: >-
  Unified orchestrator for all intelligence operations using Llama Index workflows. Handles document ingestion,
  pattern learning, quality assessment, semantic analysis, and relationship detection workflows.
input_model:
  name: "ModelOrchestratorInput"
  module: "omniintelligence.nodes.node_intelligence_orchestrator.models"
  description: "Input containing operation type, entity ID, payload, and correlation ID."
output_model:
  name: "ModelOrchestratorOutput"
  module: "omniintelligence.nodes.node_intelligence_orchestrator.models"
  description: "Output containing workflow execution results, intents, and any errors."
# Workflow Coordination Configuration
# ====================================
# Defines the Llama Index workflow execution graph for intelligence operations.
# Each workflow is triggered by the operation_type field in the input model.
workflow_coordination:
  workflow_definition:
    workflow_metadata:
      workflow_name: "intelligence_workflow"
      workflow_version:
        major: 1
        minor: 0
        patch: 0
      description: "Routes intelligence operations to appropriate compute/effect nodes"
    execution_graph:
      nodes:
        - node_id: "receive_request"
          node_type: EFFECT_GENERIC
          description: "Receive intelligence operation request"
          step_config:
            event_pattern: ["intelligence.*"]
        # Note: route_operation is an internal orchestration step, not a compute delegator.
        # It routes based on operation_type to determine which compute/effect nodes to invoke.
        - node_id: "route_operation"
          node_type: ORCHESTRATOR_INTERNAL
          description: "Route operation based on EnumIntelligenceOperationType"
          depends_on: ["receive_request"]
          step_config:
            routing_field: "operation_type"
            routing_strategy: "operation_type_match"
        # Note: execute_compute is a dynamic dispatcher that invokes the appropriate
        # compute node based on the routing decision from route_operation.
        - node_id: "execute_compute"
          node_type: ORCHESTRATOR_INTERNAL
          description: "Dispatch to appropriate compute node based on operation routing"
          depends_on: ["route_operation"]
          step_config:
            dispatch_strategy: "dynamic_compute_selection"
            available_compute_nodes:
              - pattern_matching_compute
              - quality_scoring_compute
              - semantic_analysis_compute
        - node_id: "execute_effects"
          node_type: EFFECT_GENERIC
          description: "Execute effect nodes for persistence"
          depends_on: ["execute_compute"]
          step_config:
            # Effect nodes are handled via intelligence_adapter_effect
            effect_nodes: []
        - node_id: "publish_outcome"
          node_type: EFFECT_GENERIC
          description: "Publish workflow outcome event"
          depends_on: ["execute_effects"]
          step_config:
            event_type: "IntelligenceOperationResult"
    coordination_rules:
      execution_mode: parallel
      parallel_execution_allowed: true
      max_parallel_branches: 5
      failure_recovery_strategy: retry
      max_retries: 3
      recovery_enabled: true
      timeout_ms: 300000
      checkpoint_enabled: true
      checkpoint_interval_ms: 10000
      state_persistence_enabled: true
      rollback_enabled: true
# Consumed Events
# ===============
consumed_events:
  - topic: "{env}.archon-intelligence.intelligence.code-analysis-requested.v1"
    event_type: "CodeAnalysisRequested"
  - topic: "{env}.archon-intelligence.intelligence.document-ingestion-requested.v1"
    event_type: "DocumentIngestionRequested"
  - topic: "{env}.archon-intelligence.intelligence.pattern-learning-requested.v1"
    event_type: "PatternLearningRequested"
  - topic: "{env}.archon-intelligence.intelligence.quality-assessment-requested.v1"
    event_type: "QualityAssessmentRequested"
# Published Events
# ================
published_events:
  - topic: "{env}.archon-intelligence.intelligence.code-analysis-completed.v1"
    event_type: "CodeAnalysisCompleted"
  - topic: "{env}.archon-intelligence.intelligence.code-analysis-failed.v1"
    event_type: "CodeAnalysisFailed"
  - topic: "{env}.archon-intelligence.intelligence.document-ingested.v1"
    event_type: "DocumentIngested"
  - topic: "{env}.archon-intelligence.intelligence.pattern-learned.v1"
    event_type: "PatternLearned"
  - topic: "{env}.archon-intelligence.intelligence.quality-assessed.v1"
    event_type: "QualityAssessed"
# Dependencies
# ============
dependencies:
  - name: "pattern_matching_compute"
    type: "node"
    module: "omniintelligence.nodes.node_pattern_matching_compute"
    description: "Compute node for pattern matching."
  - name: "quality_scoring_compute"
    type: "node"
    module: "omniintelligence.nodes.node_quality_scoring_compute"
    description: "Compute node for quality scoring."
  - name: "semantic_analysis_compute"
    type: "node"
    module: "omniintelligence.nodes.node_semantic_analysis_compute"
    description: "Compute node for semantic analysis."
  - name: "intelligence_reducer"
    type: "node"
    module: "omniintelligence.nodes.node_intelligence_reducer"
    description: "Reducer for FSM state management."
  - name: "intelligence_adapter_effect"
    type: "node"
    module: "omniintelligence.nodes.intelligence_adapter"
    description: "Effect node for intelligence API operations via adapter pattern."
# Error Handling Configuration
# ============================
error_handling:
  retry_policy:
    max_retries: 3
    initial_delay_ms: 2000
    max_delay_ms: 30000
    exponential_base: 2
    retry_on:
      - "ComputeExecutionError"
      - "EffectExecutionError"
      - "ConnectionError"
      - "TimeoutError"
  circuit_breaker:
    enabled: true
    failure_threshold: 5
    reset_timeout_ms: 60000
  error_types:
    - name: "ComputeExecutionError"
      error_code: "ORCH_001"
      description: "Error during compute node execution"
      recoverable: true
      retry_strategy: "exponential_backoff"
    - name: "EffectExecutionError"
      error_code: "ORCH_002"
      description: "Error during effect node execution"
      recoverable: true
      retry_strategy: "exponential_backoff"
    - name: "WorkflowTimeoutError"
      error_code: "ORCH_003"
      description: "Workflow execution exceeded timeout"
      recoverable: false
      retry_strategy: "none"
# Health Check
# ============
health_check:
  enabled: true
  endpoint: "/health"
  interval_seconds: 30
# Metadata
# ========
metadata:
  author: "OmniNode Team"
  created: "2025-11-14"
  updated: "2026-01-20"
  tags:
    - "ONEX"
    - "orchestrator"
    - "intelligence"
    - "workflows"
    - "llama-index"
