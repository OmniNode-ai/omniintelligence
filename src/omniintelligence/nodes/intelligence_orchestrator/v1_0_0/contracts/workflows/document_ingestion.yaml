name: document_ingestion_workflow
version:
  major: 1
  minor: 0
  patch: 0

description: |
  Llama Index workflow for document ingestion.
  Orchestrates vectorization, entity extraction, and relationship detection.

workflow_type: sequential_with_parallel

steps:
  - name: validate_input
    type: validation
    description: Validate document input and metadata
    handler: validate_document_input
    on_error: fail_immediately

  - name: emit_reducer_intent
    type: intent
    description: Emit intent to reducer to update FSM state to PROCESSING
    handler: emit_state_update_intent
    intent_type: STATE_UPDATE
    payload:
      fsm_type: INGESTION
      new_state: PROCESSING

  - name: parallel_processing
    type: parallel
    description: Execute vectorization and entity extraction in parallel
    steps:
      - name: vectorize_document
        type: compute
        description: Generate embeddings for document
        compute_node: vectorization_compute
        input:
          content: ${input.content}
          metadata: ${input.metadata}
        output: vectorization_result

      - name: extract_entities
        type: compute
        description: Extract entities from document
        compute_node: entity_extraction_compute
        input:
          content: ${input.content}
          language: ${input.metadata.language}
        output: extraction_result

  - name: store_vectors
    type: effect
    description: Store embeddings in Qdrant
    effect_node: qdrant_vector_effect
    input:
      document_id: ${input.document_id}
      embeddings: ${vectorization_result.embeddings}
      metadata: ${input.metadata}
    depends_on:
      - vectorize_document

  - name: detect_relationships
    type: compute
    description: Detect relationships between extracted entities
    compute_node: relationship_detection_compute
    input:
      entities: ${extraction_result.entities}
      context: ${input.metadata}
    depends_on:
      - extract_entities
    output: relationship_result

  - name: store_graph
    type: effect
    description: Store entities and relationships in Memgraph
    effect_node: memgraph_graph_effect
    input:
      entities: ${extraction_result.entities}
      relationships: ${relationship_result.relationships}
      document_id: ${input.document_id}
    depends_on:
      - detect_relationships

  - name: publish_completion_event
    type: effect
    description: Publish document ingestion completion event to Kafka
    effect_node: kafka_event_effect
    input:
      topic: enrichment.completed.v1
      event_type: DOCUMENT_INGESTED
      payload:
        document_id: ${input.document_id}
        entities_count: ${extraction_result.entities.length}
        relationships_count: ${relationship_result.relationships.length}
        vectorized: ${vectorization_result.success}
      correlation_id: ${input.correlation_id}

  - name: update_fsm_state
    type: intent
    description: Emit intent to update FSM state to INDEXED
    handler: emit_state_update_intent
    intent_type: STATE_UPDATE
    payload:
      fsm_type: INGESTION
      entity_id: ${input.document_id}
      new_state: INDEXED
      metadata:
        entities_extracted: ${extraction_result.entities.length}
        relationships_found: ${relationship_result.relationships.length}

# Error handling for workflow
error_handling:
  on_step_failure:
    - name: publish_error_event
      type: effect
      effect_node: kafka_event_effect
      input:
        topic: enrichment.failed.v1
        event_type: DOCUMENT_INGESTION_FAILED
        payload:
          document_id: ${input.document_id}
          failed_step: ${error.step}
          error_message: ${error.message}
        correlation_id: ${input.correlation_id}

    - name: update_fsm_to_failed
      type: intent
      handler: emit_state_update_intent
      intent_type: STATE_UPDATE
      payload:
        fsm_type: INGESTION
        entity_id: ${input.document_id}
        new_state: FAILED
        metadata:
          error: ${error.message}
          failed_at_step: ${error.step}

  retry_policy:
    max_retries: 3
    retry_on_steps:
      - vectorize_document
      - store_vectors
      - store_graph
    backoff_strategy: exponential

# Performance settings
performance:
  timeout_seconds: 600
  enable_caching: true
  cache_key_template: "doc_ingest:${input.document_id}"
  cache_ttl_seconds: 300

# Monitoring
monitoring:
  track_step_duration: true
  emit_progress_events: true
  log_level: INFO
