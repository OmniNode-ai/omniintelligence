---
# ONEX Node Contract - Vectorization Compute Node
#
# This compute node generates embeddings from code and documents.
# Supports multiple embedding models and batch processing.
# Pure compute node with no side effects.
# =============================================================================
contract_version:
  major: 1
  minor: 0
  patch: 0
node_version:
  major: 1
  minor: 0
  patch: 0
name: "vectorization_compute"
node_type: "COMPUTE_GENERIC"
description: >-
  Compute node for generating embeddings from code and documents. Supports multiple embedding models and
  batch processing with result caching.
input_model:
  name: "ModelVectorizationInput"
  module: "omniintelligence.nodes.vectorization_compute.models"
  description: "Input containing content to vectorize, metadata, and model preferences."
output_model:
  name: "ModelVectorizationOutput"
  module: "omniintelligence.nodes.vectorization_compute.models"
  description: "Output containing generated embeddings and model information."
# Operations
# ==========
# Both single and batch operations use the same model fields with CONSISTENT structure.
# Batch mode is controlled by the `batch_mode` boolean flag in input.
# When batch_mode=true, content should contain newline-separated items.
#
# Output Structure (CONSISTENT for both modes):
#   - embeddings: list[list[float]] - List of embedding vectors
#     - Single mode: [[0.1, 0.2, ...]] (one vector in list)
#     - Batch mode: [[0.1, ...], [0.2, ...]] (N vectors in list)
#   - batch_count: int - Number of vectors in embeddings list
#   - embedding_dimension: int - Dimension of each vector
#
# This design ensures:
#   - Same access pattern for both modes: `for emb in output.embeddings`
#   - No flattening/parsing required
#   - Self-describing output structure
#
# Failed operations:
#   - success: false
#   - embeddings: [] (empty list)
#   - batch_count: 0
#   - embedding_dimension: 0
operations:
  - name: "vectorize"
    description: "Generate embeddings for content (single or batch based on batch_mode flag)"
    input_fields:
      - content
      - metadata
      - model_name
      - batch_mode
    output_fields:
      - success
      - embeddings
      - model_used
      - batch_count
      - embedding_dimension
      - metadata
# Dependencies
# ============
# Current: No external protocol dependencies (uses internal embedding implementation)
#
# Future Enhancement (ONEX-EMBED-001):
# ------------------------------------
# Status: Backlog - Phase 3 (v0.4.0)
# Priority: Low (current implementation functional without protocol abstraction)
# Description: Create omniintelligence.protocols module with EmbeddingModelProtocol
# Requirements:
#   - Create protocols/ directory with EmbeddingModelProtocol
#   - Define interface for embedding generation (encode, batch_encode, get_dimension)
#   - Currently no protocols directory exists
# Tracked: docs/migrations/omniarchon_to_omniintelligence.md (Phase 3 - Protocols)
# Reference: See MIGRATION_SUMMARY.md for protocol migration patterns
#
dependencies: []
# Future dependency (when ONEX-EMBED-001 is implemented):
# - name: "embedding_model"
#   type: "protocol"
#   module: "omniintelligence.protocols"
#   description: "Embedding model for vector generation"
# Error Handling Configuration
# ============================
error_handling:
  error_types:
    - name: "VectorizationValidationError"
      error_code: "VECTOR_001"
      description: "Input validation failed (e.g., empty content)"
      recoverable: false
      retry_strategy: "none"
    - name: "VectorizationComputeError"
      error_code: "VECTOR_002"
      description: "Error during embedding generation"
      recoverable: true
      retry_strategy: "immediate_retry"
    - name: "ModelNotFoundError"
      error_code: "VECTOR_003"
      description: "Requested embedding model not available"
      recoverable: false
      retry_strategy: "none"
# Health Check
# ============
health_check:
  enabled: true
  endpoint: "/health"
  interval_seconds: 30
# Metadata
# ========
metadata:
  author: "OmniNode Team"
  created: "2025-11-14"
  updated: "2026-01-18"
  tags:
    - "ONEX"
    - "compute"
    - "vectorization"
    - "embeddings"
